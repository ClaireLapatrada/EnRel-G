{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EnRel-G: Classes used in constructing a graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, label=None, tags = None):\n",
    "        \"\"\"Constructs a InputExample.\n",
    "\n",
    "        Args:\n",
    "            guid: Unique id for the example.\n",
    "            text_a: string. The untokenized text of the first sequence. For single\n",
    "            sequence tasks, only this sequence must be specified.\n",
    "            text_b: (Optional) string. The untokenized text of the second sequence.\n",
    "            Only must be specified for sequence pair tasks.\n",
    "            label: (Optional) string. The label of the example. This should be\n",
    "            specified for train and dev examples, but not for test examples.\n",
    "        \"\"\"\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label = label\n",
    "        self.tags = tags\n",
    "\n",
    "class InputFeatures(object):\n",
    "    \"\"\"A single set of features of data.\"\"\"\n",
    "\n",
    "    def __init__(self, input_ids, input_mask, segment_ids, label_id, valid_ids=None, label_mask=None, pos=None, dep = None, head = None, adj_a=None, adj_f=None):\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_id = label_id\n",
    "        self.valid_ids = valid_ids\n",
    "        self.label_mask = label_mask\n",
    "        self.adj_a = adj_a\n",
    "        self.adj_f = adj_f\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EnRel-G: Steps to creating a graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data_utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python readfile(filename)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reads .conll file to extract each line (sentences) and extract their respective labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python convert_examples_to_features(examples, label_list, max_seq_length, tokenizer, gat_type)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converts InputExample object into numerical features for training.\n",
    "- Tokenize example and label each token with part-of-speech, dependency parsing, syntactic head indices.\n",
    "- Insert [CLS] and [SEP] (start and end) token\n",
    "- Construct segment IDs for each token\n",
    "- Converts tokens and labels into numerical IDs.\n",
    "\n",
    "Returns\n",
    "A list of InputFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python construct_graphs(input_ids,tokenizer, pos_ids, dep_ids, head, max_len, type)```\n",
    "\n",
    "Build a graph based on the specified type ('AF': Returns both adjacency matrices, 'A': Returns only adj_a, 'F': Returns only adj_f)\n",
    "- Converts token id to token\n",
    "- Converts features into numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build_graph.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python normalize_adj(mx)```: normalize adjecency matrix\n",
    "\n",
    "```python normalize_features(mx)```: normalize features matrix\n",
    "\n",
    "```python acronyms(tokens)```: identifies acronym tokens based on their surroundings in the sentence\n",
    "\n",
    "```python get_edges(sentence, pos_id,dep_id, head,longest_token_sequence_in_batch)```: \n",
    "NOTE: Sentence is each line of the .conll file\n",
    "- Lexicon rule (Coreference Graph): edges between\n",
    "    * Exact similar token\n",
    "    * The lemmatized token (like a root word) is the same as the token\n",
    "    * The acronyms and their definition\n",
    "- Dependency rule (Dependency Graph): edges between\n",
    "    * Two words that are subject and object of the same verb\n",
    "    * Word and its syntactic head\n",
    "    * additional features like compounds\n",
    "\n",
    "```python edge2adj(edges,longest_token_sequence_in_batch)```: Converts the list of edges into a symmetric adjacency matrix\n",
    "\n",
    "```python buildgraph(sentences,max_len, pos_ids, dep_ids, head)```: get the edges and construct the adjecency matrix, process into a torch tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Would it be possible to provide the graph or the type of nodes and edges we want to extract?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, the graph is constructed all manually. We can specify what type of edges to add in ```python get_edges()```. The node is the token as a default, we can also change that manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
